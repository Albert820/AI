{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4 Diabetes Prediction using Rule Based Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGXkgSL0Q5cc",
        "outputId": "0a74e92e-5bfa-47ee-90bb-829dc647bbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "  \n",
        "# Function importing Dataset\n",
        "def importdata():\n",
        "    balance_data = pd.read_csv(\"dibetic_data.txt\", header = None)\n",
        "\n",
        "    \"\"\"\n",
        "    balance_data = pd.read_csv(\n",
        "'https://archive.ics.uci.edu/ml/machine-learning-'+\n",
        "'databases/balance-scale/balance-scale.data',\n",
        "    sep= ',', header = None)   \n",
        "    \"\"\"\n",
        "\n",
        "    # Printing the dataswet shape\n",
        "    print (\"Dataset Length: \", len(balance_data))\n",
        "    print (\"Dataset Shape: \", balance_data.shape)\n",
        "      \n",
        "    # Printing the dataset obseravtions\n",
        "    print (\"Dataset: \",balance_data.head())\n",
        "    return balance_data\n",
        "\n",
        "def tarin_using_entropy(X_train, X_test, y_train):\n",
        "  \n",
        "    # Decision tree with entropy\n",
        "    clf_entropy = DecisionTreeClassifier(\n",
        "            criterion = \"entropy\", random_state = 100,\n",
        "            max_depth = 3, min_samples_leaf = 1)\n",
        "  \n",
        "    # Performing training\n",
        "    clf_entropy.fit(X_train, y_train)\n",
        "    return clf_entropy\n",
        "\n",
        "# Function to make predictions\n",
        "def prediction(X_test, clf_object):\n",
        "  \n",
        "    # Predicton on test with giniIndex\n",
        "    y_pred = clf_object.predict(X_test)\n",
        "    print(\"Predicted values:\")\n",
        "    print(y_pred)\n",
        "    return y_pred\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def cal_accuracy(y_test, y_pred):\n",
        "      \n",
        "    print(\"Confusion Matrix: \",\n",
        "        confusion_matrix(y_test, y_pred))\n",
        "      \n",
        "    print (\"Accuracy : \",\n",
        "    accuracy_score(y_test,y_pred)*100)\n",
        "      \n",
        "    print(\"Report : \",\n",
        "    classification_report(y_test, y_pred))\n",
        "\n",
        "# Function to split the dataset\n",
        "def splitdataset(balance_data):\n",
        "  \n",
        "    # Separating the target variable\n",
        "    X = balance_data.values[:, 0:3]\n",
        "    Y = balance_data.values[:, 3]\n",
        "    #X = balance_data.values[:, 1:5]\n",
        "    #Y = balance_data.values[:, 0] \n",
        "\n",
        "    # Splitting the dataset into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split( \n",
        "    X, Y, test_size = 0.3, random_state = 100)\n",
        "      \n",
        "    return X, Y, X_train, X_test, y_train, y_test\n",
        "\n",
        "def main():\n",
        "      \n",
        "    # Building Phase\n",
        "    data = importdata()\n",
        "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
        "    \n",
        "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
        "      \n",
        "    print(\"X_train:\\n {}\".format(X_train))\n",
        "    print(\"X_test:\\n {}\".format(X_test))\n",
        "    print(\"y_test:\\n {}\".format(y_test))\n",
        "\n",
        "    print(\"Results Using Entropy:\")\n",
        "    # Prediction using entropy\n",
        "    y_pred_entropy = prediction(X_test, clf_entropy)\n",
        "    cal_accuracy(y_test, y_pred_entropy)\n",
        "\n",
        "\n",
        "# Calling main function\n",
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dORctdjoRL4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff032ec-6b62-45a2-db3e-67f877b35849"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Length:  10\n",
            "Dataset Shape:  (10, 4)\n",
            "Dataset:     0  1     2  3\n",
            "0  0  1  2.54  0\n",
            "1  1  0  1.31  0\n",
            "2  1  1  1.13  0\n",
            "3  0  0  2.07  0\n",
            "4  1  1  2.34  1\n",
            "X_train:\n",
            " [[1.   0.   0.55]\n",
            " [1.   1.   2.34]\n",
            " [1.   1.   1.13]\n",
            " [0.   1.   2.54]\n",
            " [0.   0.   2.07]\n",
            " [1.   1.   8.29]\n",
            " [1.   0.   1.14]]\n",
            "X_test:\n",
            " [[1.   1.   3.12]\n",
            " [0.   1.   2.48]\n",
            " [1.   0.   1.31]]\n",
            "y_test:\n",
            " [1. 0. 0.]\n",
            "Results Using Entropy:\n",
            "Predicted values:\n",
            "[1. 0. 0.]\n",
            "Confusion Matrix:  [[2 0]\n",
            " [0 1]]\n",
            "Accuracy :  100.0\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         2\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ch3SaMXAZGbe"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}